<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> research | afchapman </title> <meta name="author" content="Angus F. Chapman"> <meta name="description" content="some topics of interest I have been working on"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A7%A0&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://afchapman.github.io/research/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> afchapman </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/research/">research <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">research</h1> <p class="post-description">some topics of interest I have been working on</p> </header> <article> <div class="post"> <article> <hr> <div class="profile float-right"> </div> <div class="clearfix"> <h2 id="feature-based-attention">feature-based attention</h2> <p>Researchers have typically divided up the study of attention into several different <em>domains</em>, reflecting the different types of visual information that can be present in the world. Attention can be directed towards different spatial locations, objects, features, or times, for example. Feature-based attention refers to how we attend to basic visual features, such as colors, orientations, or motion directions.</p> <p>In my research, I investigated some fundamental aspects of feature-based attention, such as:</p> <ul> <li>How broadly or narrowly can we focus our attention to features? <a class="citation" href="#ChapmanTargVar">(Chapman &amp; Störmer, 2023; Özkan et al., 2025)</a> </li> <li>How is the efficiency of attention affected by the similarity between target and distractor features? <a class="citation" href="#ChapmanFeatSimBeh">(Chapman &amp; Störmer, 2022; Chapman &amp; Störmer, 2024)</a> </li> <li>Can feature-based attention account for the findings of object-based attention? <a class="citation" href="#ChapmanSprAtt">(Chapman &amp; Störmer, 2021)</a> </li> </ul> <h4 id="relevant-papers">relevant papers</h4> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#366092"> <div>Behavior</div> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/targvar.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="targvar.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ChapmanTargVar" class="col-sm-8"> <div class="title">Efficient tuning of attention to narrow and broad ranges of task-relevant feature values</div> <div class="author"> <em>Angus F. Chapman</em> and Viola S. Störmer </div> <div class="periodical"> <em>Visual Cognition</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1080/13506285.2023.2192993" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://osf.io/uf4k6/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Data</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#988514"> <div>EEG</div> </abbr> </div> <div id="Ozkan_JNeuro_2025" class="col-sm-8"> <div class="title">Zooming in and out: Selective attention modulates color signals in early visual cortex for narrow and broad ranges of task-relevant features</div> <div class="author"> Mert Özkan, <em>Angus F. Chapman</em>, and Viola S. Störmer </div> <div class="periodical"> <em>Journal of Neuroscience</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1523/JNEUROSCI.2097-24.2025" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://osf.io/qx94k/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Data</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#366092"> <div>Behavior</div> </abbr> </div> <div id="ChapmanFeatSimBeh" class="col-sm-8"> <div class="title">Feature similarity is non-linearly related to attentional selection: evidence from visual search and sustained attention tasks</div> <div class="author"> <em>Angus F. Chapman</em> and Viola S. Störmer </div> <div class="periodical"> <em>Journal of Vision</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1167/jov.22.8.4" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://osf.io/swdqk/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Data</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#366092"> <div>Behavior</div> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/app24.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="app24.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ChapmanSim_2024" class="col-sm-8"> <div class="title">Target-distractor similarity predicts visual search efficiency but only for highly similar features</div> <div class="author"> <em>Angus F. Chapman</em> and Viola S. Störmer </div> <div class="periodical"> <em>Attention, Perception, &amp; Psychophysics</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.3758/s13414-024-02954-y" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://osf.io/u5trm/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Data</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#366092"> <div>Behavior</div> </abbr> </div> <div id="ChapmanSprAtt" class="col-sm-8"> <div class="title">Feature-based attention is not confined by object boundaries: spatially global enhancement of irrelevant features</div> <div class="author"> <em>Angus F. Chapman</em> and Viola S. Störmer </div> <div class="periodical"> <em>Psychonomic Bulletin and Review</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.3758/s13423-021-01897-x" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://osf.io/7pfyx" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Data</a> </div> </div> </div> </li> </ol> </div> </div> <hr> <div class="profile float-right"> </div> <div class="clearfix"> <h2 id="representational-geometry-and-attention">representational geometry and attention</h2> <p>Representational geometry is a computational framework that aims to understand the structure of neural activity and how it relates to processing of different types of information. One of the key concepts in representational geometry is <em>similarity</em>—the idea being that things in the real world that we perceive to be similar are also likely to generate similar patterns of activity in the brain.</p> <p>Recently, I have been interested in exploring how representational geometry can account for different experimental findings related to attention. In one line of research, I found that when attending to particular colors, people perceive other colors as being <em>less similar</em> to the target, suggesting that their perception was biased by attention <a class="citation" href="#ChapmanFeatWarp">(Chapman et al., 2023)</a>. Extending on this, in my postdoc I have completed a project where we measured how attention affects the representational geometry of orientation <a class="citation" href="#ChapmanTriadAttn">(Chapman et al., 2025)</a>.</p> <p>Reviewing a wide range of attention literature, we have also argues that many findings, spanning different domains of attention (spatial, feature-based, etc.), can potentially be unfied within this framework of representational geometry <a class="citation" href="#ChapmanTICS_2024">(Chapman &amp; Störmer, 2024)</a>.</p> <h4 id="relevant-papers">relevant papers</h4> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#366092"> <div>Behavior</div> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/featwarp.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="featwarp.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ChapmanFeatWarp" class="col-sm-8"> <div class="title">Feature-based attention warps the perception of visual features</div> <div class="author"> <em>Angus F. Chapman</em>, Chaipat Chunharas, and Viola S. Störmer </div> <div class="periodical"> <em>Scientific Reports</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1038/s41598-023-33488-2" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://osf.io/w9kc5/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Data</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#366092"> <div>Behavior</div> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/triadattn.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="triadattn.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ChapmanTriadAttn" class="col-sm-8"> <div class="title">Attention reshapes the representational geometry of a perceptual feature space</div> <div class="author"> <em>Angus F. Chapman</em>, Melissa Allouche, and Rachel N. Denison </div> <div class="periodical"> <em>bioRxiv</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1101/2025.08.28.672962" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Preprint</a> <a href="https://github.com/denisonlab/attn_geo" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#238762"> <div>Review</div> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/tics24_alt.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tics24_alt.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ChapmanTICS_2024" class="col-sm-8"> <div class="title">Representational spaces as a unifying framework for attention</div> <div class="author"> <em>Angus F. Chapman</em> and Viola S. Störmer </div> <div class="periodical"> <em>Trends in Cognitive Sciences</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1016/j.tics.2024.01.002" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> </div> </div> </li> </ol> </div> </div> <hr> <div class="profile float-right"> </div> <div class="clearfix"> <h2 id="computational-modeling">computational modeling</h2> <p>In my postdoc, I have been working to develop computational models of visual processing that take into account the temporal dynamics of the brain. We have recently submitted a manuscript for publication where we tested a new model, the Dynamic Spatiotemporal Attention and Normalization model (D-STAN), and measured its ability to reproduce several known non-linear temporal response properties <a class="citation" href="#ChapmanDSTAN">(Chapman &amp; Denison, 2025)</a>.</p> <p>In ongoing work, I am assessing how trade-offs in attention across time might be accounted for by the dynamics of normalization in D-STAN <a class="citation" href="#Chapman_SfN24">(Chapman &amp; Denison, 2024)</a>.</p> <p>Going forward, I plan to incorporate computational modeling as a core aspect in my research. I am particularly excited by the idea of modeling the effects of attention in neural populations, and seeing how these changes are related to the perceptual and neural representation of different stimuli.</p> <h4 id="relevant-papers">relevant papers</h4> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#8b4c9a"> <div>Theory</div> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/dstan.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="dstan.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ChapmanDSTAN" class="col-sm-8"> <div class="title">A dynamic spatiotemporal normalization model for continuous vision</div> <div class="author"> <em>Angus F. Chapman</em> and Rachel N. Denison </div> <div class="periodical"> <em>bioRxiv</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1101/2025.03.06.641906" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Preprint</a> <a href="https://github.com/denisonlab/dstan" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://osf.io/qy9pa/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Data</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#056091"> <a href="https://sfn.org/" rel="external nofollow noopener" target="_blank">SfN</a> </abbr> </div> <div id="Chapman_SfN24" class="col-sm-8"> <div class="title">Temporal normalization incentivizes attentional tradeoffs across time.</div> <div class="author"> <em>Angus F. Chapman</em> and Rachel N. Denison </div> <div class="periodical"> <em>Poster presented at Society for Neuroscience, Chicago, IL, USA.</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="/assets/pdf/confposters/ChapmanDenison_SfN24.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> </div> </div> </li> </ol> </div> </div> </article> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Angus F. Chapman. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-9B7LD3G8GV"></script> <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'G-9B7LD3G8GV');
  </script> <script defer src="/assets/js/google-analytics-setup.js"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>